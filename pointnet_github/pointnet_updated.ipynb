{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efa484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 11:46:33.407433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import keras\n",
    "import tf_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5b892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size, num_point):\n",
    "    pointclouds_pl = tf.placeholder(tf.float32, shape=(batch_size, num_point, 3))\n",
    "    labels_pl = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return pointclouds_pl, labels_pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2fa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(point_cloud, is_training, bn_decay=None):\n",
    "    \"\"\" Classification PointNet, input is BxNx3, output Bx40 \"\"\"\n",
    "    batch_size = point_cloud.get_shape()[0]\n",
    "    num_point = point_cloud.get_shape()[1]\n",
    "    end_points = {}\n",
    "    input_image = tf.expand_dims(point_cloud, -1)\n",
    "    \n",
    "    # Point functions (MLP implemented as conv2d)\n",
    "    net = tf_util.conv2d(input_image, 64, [1,3],\n",
    "                         padding='VALID', stride=[1,1],\n",
    "                         bn=True, is_training=is_training,\n",
    "                         scope='conv1', bn_decay=bn_decay)\n",
    "    net = tf_util.conv2d(net, 64, [1,1],\n",
    "                         padding='VALID', stride=[1,1],\n",
    "                         bn=True, is_training=is_training,\n",
    "                         scope='conv2', bn_decay=bn_decay)\n",
    "    net = tf_util.conv2d(net, 64, [1,1],\n",
    "                         padding='VALID', stride=[1,1],\n",
    "                         bn=True, is_training=is_training,\n",
    "                         scope='conv3', bn_decay=bn_decay)\n",
    "    net = tf_util.conv2d(net, 128, [1,1],\n",
    "                         padding='VALID', stride=[1,1],\n",
    "                         bn=True, is_training=is_training,\n",
    "                         scope='conv4', bn_decay=bn_decay)\n",
    "    net = tf_util.conv2d(net, 1024, [1,1],\n",
    "                         padding='VALID', stride=[1,1],\n",
    "                         bn=True, is_training=is_training,\n",
    "                         scope='conv5', bn_decay=bn_decay)\n",
    "\n",
    "    # Symmetric function: max pooling\n",
    "    net = tf_util.max_pool2d(net, [num_point,1],\n",
    "                             padding='VALID', scope='maxpool')\n",
    "    \n",
    "    # MLP on global point cloud vector\n",
    "    net = tf.reshape(net, [batch_size, -1])\n",
    "    net = tf_util.fully_connected(net, 512, bn=True, is_training=is_training,\n",
    "                                  scope='fc1', bn_decay=bn_decay)\n",
    "    net = tf_util.fully_connected(net, 256, bn=True, is_training=is_training,\n",
    "                                  scope='fc2', bn_decay=bn_decay)\n",
    "    net = tf_util.dropout(net, keep_prob=0.7, is_training=is_training,\n",
    "                          scope='dp1')\n",
    "    net = tf_util.fully_connected(net, 40, activation_fn=None, scope='fc3')\n",
    "\n",
    "    return net, end_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c171630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(pred, label, end_points):\n",
    "    \"\"\" pred: B*NUM_CLASSES,\n",
    "        label: B, \"\"\"\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=label)\n",
    "    classify_loss = tf.reduce_mean(loss)\n",
    "    tf.summary.scalar('classify loss', classify_loss)\n",
    "    return classify_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db3975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'fc3/BiasAdd:0' shape=(32, 40) dtype=float32>, {})\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    with tf.Graph().as_default():\n",
    "        inputs = tf.zeros((32,1024,3))\n",
    "        outputs = get_model(inputs, tf.constant(True))\n",
    "        print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a793400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3321ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f58d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d45c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436fef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785a87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
